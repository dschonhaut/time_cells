{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parallel_in_python3.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path as op\n",
    "from glob import glob\n",
    "import shutil\n",
    "from collections import OrderedDict as od\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from time import time\n",
    "from cluster_helper.cluster import cluster_view\n",
    "sys.path.append('/home1/dscho/code/general')\n",
    "import data_io as dio \n",
    "from time_cells import spike_sorting, spike_preproc, events_preproc, events_proc, time_bin_analysis, remapping, pop_decoding, time_cell_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_time_bins_parallel(ii):\n",
    "    import sys\n",
    "    import os\n",
    "    from time import sleep\n",
    "    import numpy as np\n",
    "    sys.path.append('/home1/dscho/code/general')\n",
    "    import data_io as dio \n",
    "    sys.path.append('/home1/dscho/code/projects/time_cells')\n",
    "    import time_bin_analysis\n",
    "    \n",
    "    # Take a nap.\n",
    "    sleep_secs = int(60 * np.random.rand())\n",
    "    sleep(sleep_secs)\n",
    "    \n",
    "    try:\n",
    "        n_perms = 10\n",
    "        spikes, event_times = dio.open_pickle('/home1/dscho/projects/time_cells/analysis/classifiers/tmp_inputs.pkl')\n",
    "        \n",
    "        analysis_dir = '/home1/dscho/projects/time_cells/analysis'\n",
    "        output_f = os.path.join(analysis_dir, 'classifiers', 'LinearSVM-Delay1_Delay2-20_time_bins-{}perms-{}.pkl'.format(n_perms, ii))\n",
    "        output = time_bin_analysis.classify_time_bins(spikes, \n",
    "                                                      event_times, \n",
    "                                                      ['Delay1', 'Delay2'], \n",
    "                                                      n_time_bins=20, \n",
    "                                                      k=6, \n",
    "                                                      n_perms=n_perms,\n",
    "                                                      save_as=output_f)\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-classify_time_bins_parallel_{}'.format(ii)\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')\n",
    "            \n",
    "    return None\n",
    "\n",
    "\n",
    "def fr_by_time_vs_null_parallel(info):\n",
    "    import sys\n",
    "    import os\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    sys.path.append('/home1/dscho/code/general')\n",
    "    sys.path.append('/home1/dscho/code/projects/time_cells')\n",
    "    import data_io as dio\n",
    "    import events_preproc\n",
    "    import time_bin_analysis\n",
    "    from time import sleep\n",
    "    import numpy as np\n",
    "    \n",
    "    # Take a nap.\n",
    "    sleep_secs = int(300 * np.random.rand())\n",
    "    sleep(sleep_secs)\n",
    "    \n",
    "    try:\n",
    "        subj_sess = info['subj_sess']\n",
    "        chan = info['chan']\n",
    "        unit = info['unit']\n",
    "        game_states = info['game_states']\n",
    "        n_time_bins = info['n_time_bins']\n",
    "\n",
    "        n_perms = 1000\n",
    "        analysis_dir = '/scratch/dscho/time_cells/analysis/'\n",
    "        input_f = os.path.join(analysis_dir, 'spikes', \n",
    "                               '{}-CSC{}-unit{}-spikes.pkl'\n",
    "                               .format(subj_sess, chan, unit))\n",
    "        fr_train = dio.open_pickle(input_f)['fr_train']\n",
    "        event_times = events_preproc.create_event_time_bins(subj_sess)\n",
    "        output_f = os.path.join(analysis_dir, 'spikes_by_time_bin',\n",
    "                                '{}-CSC{}-unit{}-{}-spikes_by_time_bin.pkl'\n",
    "                                .format(subj_sess, chan, unit, '_'.join(game_states)))\n",
    "\n",
    "        output = time_bin_analysis.fr_by_time_vs_null(fr_train=fr_train, \n",
    "                                                      event_times=event_times, \n",
    "                                                      game_states=game_states, \n",
    "                                                      n_time_bins=n_time_bins, \n",
    "                                                      n_perms=n_perms,\n",
    "                                                      save_as=output_f)\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-save_phase_vectors_parallel-{}-chan{}-unit{}-{}'.format(subj_sess, chan, unit, '_'.join(game_states))\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')\n",
    "            \n",
    "    return None\n",
    "\n",
    "\n",
    "def event_fr_parallel(spikes_f):\n",
    "    import sys\n",
    "    import os\n",
    "    from time import sleep\n",
    "    import numpy as np\n",
    "    sys.path.append('/home1/dscho/code/general')\n",
    "    import data_io as dio \n",
    "    sys.path.append('/home1/dscho/code/projects/time_cells')\n",
    "    import events_preproc\n",
    "    import spike_preproc\n",
    "    \n",
    "    # Take a nap.\n",
    "    sleep_secs = int(360 * np.random.rand())\n",
    "    sleep(sleep_secs)\n",
    "    \n",
    "    try:\n",
    "        # Load spike data for the neuron.\n",
    "        spikes = dio.open_pickle(spikes_f)\n",
    "        subj_sess = spikes['subj_sess']\n",
    "\n",
    "        # Load events and event times.\n",
    "        events = events_preproc.format_events(subj_sess,\n",
    "                                              overwrite=False,\n",
    "                                              save_output=False,\n",
    "                                              verbose=False)\n",
    "#         trial_times = events_preproc.trial_intervals(events)\n",
    "        event_times = events_preproc.create_event_time_bins(subj_sess,\n",
    "                                                            events=events,\n",
    "                                                            overwrite=True,\n",
    "                                                            save_output=False,\n",
    "                                                            verbose=False)\n",
    "\n",
    "        # Calculate the firing rate for each trial and trial phase time bin.\n",
    "        output = spike_preproc.event_fr(spikes,\n",
    "#                                         trial_times=trial_times, \n",
    "                                        event_times=event_times,\n",
    "#                                         include_trial_null=True,\n",
    "                                        include_event_null=True,\n",
    "                                        sigma=500,\n",
    "                                        overwrite=False,\n",
    "                                        save_output=True,\n",
    "                                        verbose=False)\n",
    "        \n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-event_fr_parallel-{}'.format('-'.join(os.path.basename(spikes_f[0]).split('-')[:3]))\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def calc_mean_fr_by_time_parallel(f):\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append('/home1/dscho/code/projects/time_cells')\n",
    "    import time_bin_analysis\n",
    "    \n",
    "    try:\n",
    "        output = time_bin_analysis.calc_mean_fr_by_time(f,\n",
    "                                                        overwrite=False,\n",
    "                                                        save_output=True,\n",
    "                                                        verbose=False)\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-calc_mean_fr_by_time_parallel-{}'.format('-'.join(os.path.basename(f[0]).split('-')[:3]))\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')\n",
    "    \n",
    "    return None\n",
    "\n",
    "def calc_fr_by_time_and_pos_parallel(f):\n",
    "    import sys\n",
    "    import os\n",
    "    import inspect\n",
    "    import traceback\n",
    "    sys.path.append('/home1/dscho/code/general')\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    import data_io as dio\n",
    "    from time_cells.place_analysis import calc_fr_by_time_and_pos\n",
    "    \n",
    "    try:\n",
    "        output = calc_fr_by_time_and_pos(dio.open_pickle(f),\n",
    "                                         compute_null=True,\n",
    "                                         compute_stats=True,\n",
    "                                         overwrite=True,\n",
    "                                         save_output=True,\n",
    "                                         verbose=False)\n",
    "    except:\n",
    "        func_name = inspect.stack()[1][3]\n",
    "        neuron_id = '-'.join(os.path.basename(f).split('-')[:3])\n",
    "        errf = os.path.join('/home1/dscho/logs', '{}-{}'.format(func_name, neuron_id))\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            err = traceback.format_exc()\n",
    "            f.write(err + '\\n')\n",
    "    \n",
    "    return None\n",
    "\n",
    "def compare_fr_by_time_and_pos_parallel(f):\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append('/home1/dscho/code/general')\n",
    "    import data_io as dio\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from time_cells.place_analysis import compare_fr_by_time_and_pos\n",
    "    \n",
    "    try:\n",
    "        output = compare_fr_by_time_and_pos(dio.open_pickle(f),\n",
    "                                            overwrite=False,\n",
    "                                            save_output=True,\n",
    "                                            verbose=False)\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        neuron_id = '-'.join(os.path.basename(f).split('-')[:3])\n",
    "        errf = '/home1/dscho/logs/TryExceptError-compare_fr_by_time_and_pos_parallel-{}'.format('-'.join(os.path.basename(f).split('-')[:3]))\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')\n",
    "    \n",
    "    return None\n",
    "\n",
    "def glm_fit_unit_parallel(subj_sess_neuron):\n",
    "    import sys\n",
    "    import os\n",
    "    from time import sleep\n",
    "    import numpy as np\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from time_cells.time_bin_analysis import glm_fit_unit\n",
    "    \n",
    "    # Take a nap.\n",
    "    if False:\n",
    "        sleep_secs = int(600 * np.random.rand())\n",
    "        sleep(sleep_secs)\n",
    "    \n",
    "    try:\n",
    "        subj_sess, chan, unit = subj_sess_neuron.split('-')\n",
    "        neuron = '{}-{}'.format(chan, unit)\n",
    "        output = glm_fit_unit(subj_sess,\n",
    "                              neuron,\n",
    "                              n_perm=1000,\n",
    "                              overwrite=False,\n",
    "                              save_output=True)\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-glm_fit_unit_parallel-{}'.format(subj_sess_neuron)\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')\n",
    "    \n",
    "    return None\n",
    "\n",
    "def model_unit_fr_parallel(subj_sess_neuron):\n",
    "    import sys\n",
    "    import os\n",
    "    from time import sleep\n",
    "    import numpy as np\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from time_cells.time_bin_analysis import model_unit_fr\n",
    "    \n",
    "    # Take a nap.\n",
    "    if True:\n",
    "        sleep_secs = int(1800 * np.random.rand())\n",
    "        sleep(sleep_secs)\n",
    "    \n",
    "    try:\n",
    "        subj_sess, chan, unit = subj_sess_neuron.split('-')\n",
    "        neuron = '{}-{}'.format(chan, unit)\n",
    "        output = model_unit_fr(subj_sess,\n",
    "                               neuron,\n",
    "                               model='ols',\n",
    "                               n_perm=1000,\n",
    "                               overwrite=False,\n",
    "                               save_output=True)\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-model_unit_fr_parallel-{}'.format(subj_sess_neuron)\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')\n",
    "    \n",
    "    return None\n",
    "\n",
    "def game_state_unit_fr_diff_parallel(subj_sess_neuron):\n",
    "    import sys\n",
    "    import os\n",
    "    from time import sleep\n",
    "    import numpy as np\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from time_cells.trial_phase_analysis import game_state_unit_fr_diff\n",
    "    \n",
    "    # Take a nap.\n",
    "    if False:\n",
    "        sleep_secs = int(300 * np.random.rand())\n",
    "        sleep(sleep_secs)\n",
    "    \n",
    "    try:\n",
    "        subj_sess, chan, unit = subj_sess_neuron.split('-')\n",
    "        neuron = '{}-{}'.format(chan, unit)\n",
    "        output = game_state_unit_fr_diff(neuron,\n",
    "                                         subj_sess=subj_sess,\n",
    "                                         n_perm=1000,\n",
    "                                         regress_trial=True,\n",
    "                                         perm_method='circshift',\n",
    "                                         alpha=0.05,\n",
    "                                         overwrite=False,\n",
    "                                         save_output=True)\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-game_state_unit_fr_diff-{}'.format(subj_sess_neuron)\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')\n",
    "    \n",
    "    return None\n",
    "\n",
    "def run_ols_delay_parallel(subj_sess_unit):\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from time_cells import time_bin_analysis\n",
    "    \n",
    "    proj_dir = '/home1/dscho/projects/time_cells'\n",
    "    n_perm = 10000\n",
    "    \n",
    "    try:\n",
    "        mod_pairs, ols_weights = time_bin_analysis.run_ols_delay(subj_sess_unit,\n",
    "                                                                 n_perm=n_perm,\n",
    "                                                                 alpha=0.05,\n",
    "                                                                 save_output=True,\n",
    "                                                                 overwrite=False)\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-run_ols_delay_parallel-{}'.format(subj_sess_unit)\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')\n",
    "            \n",
    "def run_ols_nav_parallel(subj_sess_unit):\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from time_cells import time_bin_analysis\n",
    "    \n",
    "    proj_dir = '/home1/dscho/projects/time_cells'\n",
    "    n_perm = 10000\n",
    "    \n",
    "    try:\n",
    "        mod_pairs, ols_weights = time_bin_analysis.run_ols_nav(subj_sess_unit,\n",
    "                                                               n_perm=n_perm,\n",
    "                                                               alpha=0.05,\n",
    "                                                               save_output=True,\n",
    "                                                               overwrite=False)\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-run_ols_nav_parallel-{}'.format(subj_sess_unit)\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457 neurons to process\n",
      "Running code for 457 operations.\n",
      "\n",
      "152 Engines running\n"
     ]
    }
   ],
   "source": [
    "# Get neurons to process.\n",
    "proj_dir = '/home1/dscho/projects/time_cells'\n",
    "fpath = op.join(proj_dir, 'analysis', 'unit_to_behav', '{}-Encoding_Retrieval-ols_model_pairs.pkl')\n",
    "pop_spikes = pop_decoding.load_pop_spikes()\n",
    "neurons = [neuron for neuron in pop_spikes.neurons if not op.exists(fpath.format(neuron))]\n",
    "print('{} neurons to process'.format(len(neurons)))\n",
    "\n",
    "# Parallel processing\n",
    "n_ops = len(neurons)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 200)), cores_per_job=1) as view:\n",
    "    output = view.map(run_ols_nav_parallel, neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time_cells import trial_phase_analysis \n",
    "reload(trial_phase_analysis)\n",
    "from time_cells.trial_phase_analysis import game_state_unit_fr_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "subj_sess_neuron = subj_sess_neurons[0]\n",
    "print(subj_sess_neuron)\n",
    "_ = game_state_unit_fr_diff_parallel(subj_sess_neuron)\n",
    "model_pairs = dio.open_pickle(op.join(proj_dir, 'analysis', 'unit_to_behav', '{}-ols-game_state-model_pairs.pkl'.format(subj_sess_neuron)))\n",
    "\n",
    "print('Done in {:.1f}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 subjects, 10 sessions\n",
      "Loading saved Events file\n",
      "13 neurons\n",
      "Running code for 13 operations.\n",
      "\n",
      "13 Engines running\n",
      "Sending a shutdown signal to the controller and engines.\n"
     ]
    }
   ],
   "source": [
    "# Load event_spikes and get the names of each neuron.\n",
    "proj_dir = '/home1/dscho/projects/time_cells'\n",
    "\n",
    "# Get sessions.\n",
    "sessions = np.unique([op.basename(f).split('-')[0] \n",
    "                      for f in glob(op.join(proj_dir, 'analysis', 'events', '*.pkl'))])\n",
    "print('{} subjects, {} sessions'.format(len(np.unique([x.split('_')[0] for x in sessions])), len(sessions)))\n",
    "\n",
    "subj_sess_neurons = []\n",
    "for subj_sess in sessions:\n",
    "    event_spikes = time_bin_analysis.load_event_spikes(subj_sess, verbose=False)\n",
    "    for neuron in event_spikes.column_map['neurons']:\n",
    "        subj_sess_neuron = '{}-{}'.format(subj_sess, neuron)\n",
    "        output_f = op.join(proj_dir, 'analysis', 'unit_to_behav', '{}-ols-game_state-model_pairs.pkl'.format(subj_sess_neuron))\n",
    "        if not op.exists(output_f):\n",
    "            subj_sess_neurons.append(subj_sess_neuron)\n",
    "print('{} neurons'.format(len(subj_sess_neurons)))\n",
    "\n",
    "# Parallel processing\n",
    "n_ops = len(subj_sess_neurons)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 200)), cores_per_job=1) as view:\n",
    "    output = view.map(game_state_unit_fr_diff_parallel, subj_sess_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 subjects, 12 sessions\n",
      "2 neurons\n",
      "U540_ses0-5-1\n",
      "Loading saved EventSpikes file\n",
      "494.8s\n",
      "U540_ses0-34-1\n",
      "Loading saved EventSpikes file\n",
      "972.9s\n",
      "Done in {:.1f}s\n"
     ]
    }
   ],
   "source": [
    "def model_unit_fr_parallel(subj_sess_neuron):\n",
    "    import sys\n",
    "    import os\n",
    "    from time import sleep\n",
    "    import numpy as np\n",
    "    sys.path.append('/home1/dscho/code/projects')\n",
    "    from time_cells.time_bin_analysis import model_unit_fr\n",
    "    \n",
    "    # Take a nap.\n",
    "    if False:\n",
    "        sleep_secs = int(1800 * np.random.rand())\n",
    "        sleep(sleep_secs)\n",
    "    try:\n",
    "        subj_sess, chan, unit = subj_sess_neuron.split('-')\n",
    "        neuron = '{}-{}'.format(chan, unit)\n",
    "        output = model_unit_fr(subj_sess,\n",
    "                               neuron,\n",
    "                               model='ols',\n",
    "                               n_perm=1000,\n",
    "                               overwrite=False,\n",
    "                               save_output=True)\n",
    "    except:\n",
    "        err = sys.exc_info()\n",
    "        errf = '/home1/dscho/logs/TryExceptError-model_unit_fr_parallel-{}'.format(subj_sess_neuron)\n",
    "        os.system('touch {}'.format(errf))\n",
    "        with open(errf, 'w') as f:\n",
    "            f.write(str(err) + '\\n')\n",
    "    \n",
    "    return None\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# Load event_spikes and get the names of each neuron.\n",
    "proj_dir = '/home1/dscho/projects/time_cells'\n",
    "\n",
    "# Get sessions.\n",
    "sessions = np.unique([op.basename(f).split('-')[0] \n",
    "                      for f in glob(op.join(proj_dir, 'analysis', 'events', '*.pkl'))])\n",
    "print('{} subjects, {} sessions'.format(len(np.unique([x.split('_')[0] for x in sessions])), len(sessions)))\n",
    "\n",
    "subj_sess_neurons = []\n",
    "for subj_sess in sessions:\n",
    "    event_spikes = time_bin_analysis.load_event_spikes(subj_sess, verbose=False)\n",
    "    for neuron in event_spikes.column_map['neurons']:\n",
    "        subj_sess_neuron = '{}-{}'.format(subj_sess, neuron)\n",
    "        #output_f = op.join(proj_dir, 'analysis', 'behav_glms', '{}-glm_results.pkl'.format(subj_sess_neuron))\n",
    "        output_f = op.join(proj_dir, 'analysis', 'unit_to_behav', '{}-ols-time_bin-model_pairs.pkl'.format(subj_sess_neuron))\n",
    "        if not op.exists(output_f):\n",
    "            subj_sess_neurons.append(subj_sess_neuron)\n",
    "print('{} neurons'.format(len(subj_sess_neurons)))\n",
    "\n",
    "# Parallel processing\n",
    "for subj_sess_neuron in subj_sess_neurons:\n",
    "    _start_time = time()\n",
    "    print(subj_sess_neuron)\n",
    "    _ = model_unit_fr_parallel(subj_sess_neuron)\n",
    "    print('{:.1f}s'.format(time() - start_time))\n",
    "\n",
    "print('Done in {:.1f}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 subjects, 12 sessions\n",
      "43 neurons\n",
      "Running code for 43 operations.\n",
      "\n",
      "4 Engines running\n",
      "Sending a shutdown signal to the controller and engines.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 16] Device or resource busy: '.nfs0000004402d418120000aa23'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCompositeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/cluster_helper/cluster.py\u001b[0m in \u001b[0;36mcluster_view\u001b[0;34m(scheduler, queue, num_jobs, cores_per_job, profile, start_wait, extra_params, retries, direct, wait_for_all_engines)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mcluster_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-858fea91ef00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcluster_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sge\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RAM.q\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores_per_job\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_unit_fr_parallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubj_sess_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<decorator-gen-146>\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, *sequences, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/client/view.py\u001b[0m in \u001b[0;36msync_results\u001b[0;34m(f, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-145>\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, *sequences, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/client/view.py\u001b[0m in \u001b[0;36msave_ids\u001b[0;34m(f, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/client/view.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, *sequences, **kwargs)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0mpf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallelFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mordered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/client/remotefunction.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, *sequences)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__ipp_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-128>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *sequences, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/client/remotefunction.py\u001b[0m in \u001b[0;36msync_view_results\u001b[0;34m(f, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_sync_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_sync_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/client/remotefunction.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *sequences, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/client/asyncresult.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/client/asyncresult.py\u001b[0m in \u001b[0;36m_resolve_result\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_success\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/error.py\u001b[0m in \u001b[0;36mcollect_exceptions\u001b[0;34m(rdict_or_list, method)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCompositeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/ipyparallel/error.py\u001b[0m in \u001b[0;36mcollect_exceptions\u001b[0;34m(rdict_or_list, method)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCompositeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCompositeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCompositeError\u001b[0m: one or more exceptions from call to method: model_unit_fr_parallel\n[Engine Exception]EngineError: Engine b'10fafb53-5e7508f6209bc927c09d5c18' died while running task '44edba9f-150adc6debd097cd9521963e'\n[Engine Exception]EngineError: Engine b'850fc4fb-5a4fa92752e653f309cd243b' died while running task '06d80945-0cf820d60050f908511c21e1'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-858fea91ef00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running code for {} operations.\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcluster_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sge\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RAM.q\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores_per_job\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_unit_fr_parallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubj_sess_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/cluster_helper/cluster.py\u001b[0m in \u001b[0;36mcluster_view\u001b[0;34m(scheduler, queue, num_jobs, cores_per_job, profile, start_wait, extra_params, retries, direct, wait_for_all_engines)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mcluster_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mcluster_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_nengines_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/cluster_helper/cluster.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_throwaway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m                 \u001b[0mdelete_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/cluster_helper/cluster.py\u001b[0m in \u001b[0;36mdelete_profile\u001b[0;34m(profile)\u001b[0m\n\u001b[1;32m   1234\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_to_remove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                 \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                         \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m _use_fd_functions = ({os.open, os.stat, os.unlink, os.rmdir} <=\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 16] Device or resource busy: '.nfs0000004402d418120000aa23'"
     ]
    }
   ],
   "source": [
    "# Load event_spikes and get the names of each neuron.\n",
    "proj_dir = '/home1/dscho/projects/time_cells'\n",
    "\n",
    "# Get sessions.\n",
    "sessions = np.unique([op.basename(f).split('-')[0] \n",
    "                      for f in glob(op.join(proj_dir, 'analysis', 'events', '*.pkl'))])\n",
    "print('{} subjects, {} sessions'.format(len(np.unique([x.split('_')[0] for x in sessions])), len(sessions)))\n",
    "\n",
    "subj_sess_neurons = []\n",
    "for subj_sess in sessions:\n",
    "    event_spikes = time_bin_analysis.load_event_spikes(subj_sess, verbose=False)\n",
    "    for neuron in event_spikes.column_map['neurons']:\n",
    "        subj_sess_neuron = '{}-{}'.format(subj_sess, neuron)\n",
    "        #output_f = op.join(proj_dir, 'analysis', 'behav_glms', '{}-glm_results.pkl'.format(subj_sess_neuron))\n",
    "        output_f = op.join(proj_dir, 'analysis', 'unit_to_behav', '{}-ols-time_bin-model_pairs.pkl'.format(subj_sess_neuron))\n",
    "        if not op.exists(output_f):\n",
    "            subj_sess_neurons.append(subj_sess_neuron)\n",
    "print('{} neurons'.format(len(subj_sess_neurons)))\n",
    "\n",
    "# Parallel processing\n",
    "n_ops = len(subj_sess_neurons)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((n_ops, 100)), cores_per_job=2) as view:\n",
    "    output = view.map(model_unit_fr_parallel, subj_sess_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob('/home1/dscho/projects/time_cells/analysis/fr_by_time_bin/mean_fr*.pkl')\n",
    "# for f in files:\n",
    "#     d, fname = os.path.split(f)\n",
    "#     s, c, u = fname.replace('mean_fr_by_time_', '').replace('ch', 'CSC').replace('.pkl', '').split('-')\n",
    "#     fnew = os.path.join(d, '{}-{}-unit{}-mean_fr_by_time.pkl'.format(s, c, u))\n",
    "#     shutil.move(f, fnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 spike files\n",
      "Running code for 67 operations.\n",
      "\n",
      "33 Engines running\n"
     ]
    }
   ],
   "source": [
    "# subj_sess = 'U530_ses0'\n",
    "# proj_dir = '/home1/dscho/projects/time_cells'\n",
    "\n",
    "# files = glob(os.path.join(proj_dir, 'analysis', 'spikes', '{}*unit*.pkl'.format(subj_sess)))\n",
    "# print('{} spike files'.format(len(files)))\n",
    "\n",
    "# # Parallel processing\n",
    "# n_ops = len(files)\n",
    "# print('Running code for {} operations.\\n'.format(n_ops))\n",
    "# with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=n_ops, cores_per_job=1) as view:\n",
    "#     output = view.map(event_fr_parallel, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 files\n"
     ]
    }
   ],
   "source": [
    "proj_dir = '/home1/dscho/projects/time_cells'\n",
    "\n",
    "files = np.sort(glob(os.path.join(proj_dir, 'analysis', 'spikes', 'U518_ses1*unit*.pkl')))\n",
    "print('{} files'.format(len(files)))\n",
    "\n",
    "# Parallel processing\n",
    "n_ops = len(files)\n",
    "print('Running code for {} operations.\\n'.format(n_ops))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=np.min((len(files), 150)), cores_per_job=1) as view:\n",
    "    output = view.map(calc_fr_by_time_and_pos_parallel, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proj_dir = '/home1/dscho/projects/time_cells'\n",
    "\n",
    "# files = np.sort(glob(os.path.join(proj_dir, 'analysis', 'fr_by_time_and_pos', 'U530_ses1*fr_by_time_and_pos.pkl')))\n",
    "# print('{} files'.format(len(files)))\n",
    "\n",
    "# # Parallel processing\n",
    "# n_ops = len(files)\n",
    "# print('Running code for {} operations.\\n'.format(n_ops))\n",
    "# with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=n_ops, cores_per_job=1) as view: \n",
    "#     output = view.map(compare_fr_by_time_and_pos_parallel, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/dscho/code/projects/time_cells/time_bin_analysis.py:277: RuntimeWarning: divide by zero encountered in log2\n",
      "  bits_per_spike = np.nansum(prob_x * (fr_given_x/mean_fr) * np.log2(fr_given_x/mean_fr))\n",
      "/home1/dscho/code/projects/time_cells/time_bin_analysis.py:277: RuntimeWarning: invalid value encountered in multiply\n",
      "  bits_per_spike = np.nansum(prob_x * (fr_given_x/mean_fr) * np.log2(fr_given_x/mean_fr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/135...\n",
      "40/135...\n",
      "60/135...\n",
      "80/135...\n",
      "100/135...\n",
      "120/135...\n",
      "Saved /home1/dscho/projects/time_cells/analysis/fr_by_time_bin/mean_fr_by_time_135_neurons.pkl\n",
      "Done in 8964.66s\n"
     ]
    }
   ],
   "source": [
    "# # Z-score trial phase time bins and calculate temporal info scores.\n",
    "# start_time = time()\n",
    "\n",
    "# game_states = [['Prepare1'], ['Delay1'], ['Encoding'], ['Prepare2'], ['Delay2'], ['Retrieval'],\n",
    "#                ['Prepare1', 'Prepare2'], ['Delay1', 'Delay2'], ['Encoding', 'Retrieval']]\n",
    "# n_perm = 1000\n",
    "# verbose = True\n",
    "\n",
    "# # Load FR files.\n",
    "# proj_dir = '/home1/dscho/projects/time_cells'\n",
    "# files = np.sort(glob(os.path.join(proj_dir, 'analysis', 'fr_by_time_bin', '*unit*.pkl')))\n",
    "# print('{} files'.format(len(files)))\n",
    "\n",
    "# mean_fr_by_time = []\n",
    "# cols = ['subj_sess', 'subj', 'sess', 'chan', 'unit', 'gameState', \n",
    "#         'fr', 'z_fr', 'z_fr_max', 'z_fr_max_ind', 'tis', 'z_tis', 'pval']\n",
    "# for i, f in enumerate(files):\n",
    "#     if np.all((verbose, i > 0, i % 20 == 0)):\n",
    "#         print('{}/{}...'.format(i, len(files)))\n",
    "#     neuron = '-'.join(os.path.basename(f).split('-')[:3]).replace('CSC', 'ch').replace('unit', '')\n",
    "#     subj_sess, chan, unit = neuron.split('-')\n",
    "#     chan = chan[2:]\n",
    "#     subj, sess = subj_sess.split('_')\n",
    "#     event_times_ = dio.open_pickle(f)['event_times']\n",
    "#     for game_state in game_states:\n",
    "#         if not np.all(np.isin(game_state, event_times_['gameState'].unique())):\n",
    "#             continue\n",
    "#         obs = np.mean(event_times_\n",
    "#                       .query(\"(gameState=={})\"\n",
    "#                       .format(game_state))['fr']\n",
    "#                       .tolist(), axis=0)\n",
    "#         null_mean = np.mean(np.mean(event_times_\n",
    "#                                     .query(\"(gameState=={})\"\n",
    "#                                     .format(game_state))['fr_null']\n",
    "#                                     .tolist(), axis=0), axis=0)\n",
    "#         null_std = np.std(np.mean(event_times_\n",
    "#                                   .query(\"(gameState=={})\"\n",
    "#                                   .format(game_state))['fr_null']\n",
    "#                                   .tolist(), axis=0), axis=0)\n",
    "#         obs_z = (obs - null_mean) / null_std\n",
    "        \n",
    "#         tis = time_bin_analysis.info_rate(obs)  # temporal information score\n",
    "#         null_tis = np.array([time_bin_analysis.info_rate(np.mean(event_times_\n",
    "#                                                                  .query(\"(gameState=={})\"\n",
    "#                                                                  .format(game_state))['fr_null']\n",
    "#                                                                  .tolist(), axis=0)[iPerm, :])\n",
    "#                              for iPerm in range(n_perm)])\n",
    "#         tis_z = (tis - np.mean(null_tis)) / np.std(null_tis)\n",
    "#         pval = (np.sum(null_tis >= tis) + 1) / (n_perm + 1)\n",
    "        \n",
    "#         mean_fr_by_time.append([subj_sess, subj, sess, chan, unit, '_'.join(game_state), \n",
    "#                                 obs, obs_z, obs_z.max(), obs_z.argmax(), tis, tis_z, pval])\n",
    "\n",
    "# mean_fr_by_time = pd.DataFrame(mean_fr_by_time, columns=cols)\n",
    "\n",
    "# # Save the output.\n",
    "# output_f = os.path.join(proj_dir, 'analysis', 'fr_by_time_bin', \n",
    "#                         'mean_fr_by_time_{}_neurons.pkl'.format(len(files)))\n",
    "# dio.save_pickle(mean_fr_by_time, output_f)\n",
    "\n",
    "# print('Done in {:.2f}s'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244\n"
     ]
    }
   ],
   "source": [
    "def format_info(x, game_states):\n",
    "    x = os.path.basename(x).split('-')\n",
    "    subj_sess = x[0]\n",
    "    chan = x[1][3:]\n",
    "    unit = x[2][4:]\n",
    "    if ('Delay1' in game_states) or ('Delay1' in game_states):\n",
    "        n_time_bins = 20\n",
    "    elif ('Encoding' in game_states) or ('Retrieval' in game_states):\n",
    "        n_time_bins = 60\n",
    "    output = od([('subj_sess', subj_sess),\n",
    "                 ('chan', chan),\n",
    "                 ('unit', unit),\n",
    "                 ('game_states', game_states),\n",
    "                 ('n_time_bins', n_time_bins)])\n",
    "    return output\n",
    "\n",
    "analysis_dir = '/scratch/dscho/time_cells/analysis'\n",
    "spike_files = glob(os.path.join(analysis_dir, 'spikes', '*CSC*.pkl'))\n",
    "\n",
    "neurons_to_process = ([format_info(x, ['Delay1', 'Delay2']) for x in spike_files] + \n",
    "                      [format_info(x, ['Encoding', 'Retrieval']) for x in spike_files])\n",
    "print(len(neurons_to_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running code for 244 operations.\n",
      "\n",
      "100 Engines running\n",
      "Sending a shutdown signal to the controller and engines.\n"
     ]
    }
   ],
   "source": [
    "# Parallel processing\n",
    "print('Running code for {} operations.\\n'.format(len(neurons_to_process)))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=100, cores_per_job=1) as view: \n",
    "    output = view.map(fr_by_time_vs_null_parallel, neurons_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get event times.\n",
    "analysis_dir = '/home1/dscho/projects/time_cells/analysis'\n",
    "event_files = glob(os.path.join(analysis_dir, 'events', '*.pkl'))\n",
    "sessions =  [os.path.basename(f).split('-')[0] for f in event_files]\n",
    "event_times = pd.concat([events_preproc.create_event_time_bins(subj_sess) for subj_sess in sessions], axis=0)\n",
    "\n",
    "# Gather spike info for each neuron.\n",
    "unit_df = spike_preproc.get_unit_df()\n",
    "cols = ['subj_sess', 'chan', 'unit', 'n_spikes', 'fr', 'hemroi', 'fr_train']\n",
    "spikes = pd.DataFrame([dio.open_pickle(row['spikes_f'])[cols] for idx, row in unit_df.iterrows()]).reset_index(drop=True)\n",
    "\n",
    "# Add time cell info for each neuron, separately for delay and task periods.\n",
    "spikes_by_time_delay = pd.DataFrame([dio.open_pickle(row['fr_by_time_delay_f']) for idx, row in unit_df.iterrows()])\n",
    "spikes_by_time_nav = pd.DataFrame([dio.open_pickle(row['fr_by_time_nav_f']) for idx, row in unit_df.iterrows()])\n",
    "spikes_by_time_delay.columns = ['{}_delay'.format(c) for c in spikes_by_time_delay.columns]\n",
    "spikes_by_time_nav.columns = ['{}_nav'.format(c) for c in spikes_by_time_nav.columns]\n",
    "spikes = pd.concat((spikes, spikes_by_time_delay, spikes_by_time_nav), axis=1)\n",
    "\n",
    "# FDR correct p-values.\n",
    "alpha = 0.05\n",
    "spikes['temporal_info_sig_delay'] = sm.stats.multipletests(spikes['temporal_info_pval_delay'], alpha=alpha, method='fdr_tsbky', is_sorted=False, returnsorted=False)[0]\n",
    "spikes['temporal_info_sig_nav'] = sm.stats.multipletests(spikes['temporal_info_pval_nav'], alpha=alpha, method='fdr_tsbky', is_sorted=False, returnsorted=False)[0]\n",
    "\n",
    "# Save these objects.\n",
    "dio.save_pickle([spikes.query(\"(temporal_info_sig_delay==True)\"), event_times], '/home1/dscho/projects/time_cells/analysis/classifiers/tmp_inputs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running code for 100 operations.\n",
      "\n",
      "60 Engines running\n",
      "Sending a shutdown signal to the controller and engines.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 16] Device or resource busy: '.nfs0000004500031d82000006a4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-adc5b2653e84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running code for {} operations.\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcluster_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sge\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RAM.q\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores_per_job\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassify_time_bins_parallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/cluster_helper/cluster.py\u001b[0m in \u001b[0;36mcluster_view\u001b[0;34m(scheduler, queue, num_jobs, cores_per_job, profile, start_wait, extra_params, retries, direct, wait_for_all_engines)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mcluster_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mcluster_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_nengines_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/cluster_helper/cluster.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_throwaway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m                 \u001b[0mdelete_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/site-packages/cluster_helper/cluster.py\u001b[0m in \u001b[0;36mdelete_profile\u001b[0;34m(profile)\u001b[0m\n\u001b[1;32m   1234\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_to_remove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                 \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                         \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m _use_fd_functions = ({os.open, os.stat, os.unlink, os.rmdir} <=\n",
      "\u001b[0;32m/home1/dscho/anaconda3/envs/memlab/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 16] Device or resource busy: '.nfs0000004500031d82000006a4'"
     ]
    }
   ],
   "source": [
    "# Parallel processing\n",
    "print('Running code for {} operations.\\n'.format(100))\n",
    "with cluster_view(scheduler=\"sge\", queue=\"RAM.q\", num_jobs=100, cores_per_job=1) as view: \n",
    "    output = view.map(classify_time_bins_parallel, np.arange(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memlab",
   "language": "python",
   "name": "memlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
